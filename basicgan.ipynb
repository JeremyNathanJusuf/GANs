{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=100):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 28*28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.net(z).view(-1, 1, 28, 28)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(28*28, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) \n",
    "        return self.net(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "def get_noise(batch_size, noise_dim):\n",
    "    return torch.randn(batch_size, noise_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/938], Loss D: 0.4048, Loss G: 1.3342\n",
      "Epoch [1/50], Step [200/938], Loss D: 0.0100, Loss G: 4.7167\n",
      "Epoch [1/50], Step [300/938], Loss D: 0.0829, Loss G: 10.9219\n",
      "Epoch [1/50], Step [400/938], Loss D: 0.0135, Loss G: 7.7133\n",
      "Epoch [1/50], Step [500/938], Loss D: 0.0907, Loss G: 9.8181\n",
      "Epoch [1/50], Step [600/938], Loss D: 0.0000, Loss G: 25.0819\n",
      "Epoch [1/50], Step [700/938], Loss D: 0.0285, Loss G: 6.6445\n",
      "Epoch [1/50], Step [800/938], Loss D: 0.1209, Loss G: 9.8888\n",
      "Epoch [1/50], Step [900/938], Loss D: 0.0559, Loss G: 13.1616\n",
      "Epoch [2/50], Step [100/938], Loss D: 0.1413, Loss G: 6.7659\n",
      "Epoch [2/50], Step [200/938], Loss D: 0.0445, Loss G: 5.6852\n",
      "Epoch [2/50], Step [300/938], Loss D: 0.4565, Loss G: 7.0318\n",
      "Epoch [2/50], Step [400/938], Loss D: 0.3708, Loss G: 6.3103\n",
      "Epoch [2/50], Step [500/938], Loss D: 0.4115, Loss G: 3.3201\n",
      "Epoch [2/50], Step [600/938], Loss D: 0.1499, Loss G: 2.8872\n",
      "Epoch [2/50], Step [700/938], Loss D: 0.0553, Loss G: 4.8515\n",
      "Epoch [2/50], Step [800/938], Loss D: 0.0978, Loss G: 5.3248\n",
      "Epoch [2/50], Step [900/938], Loss D: 0.0703, Loss G: 4.5789\n",
      "Epoch [3/50], Step [100/938], Loss D: 0.3444, Loss G: 5.2445\n",
      "Epoch [3/50], Step [200/938], Loss D: 0.2923, Loss G: 5.0130\n",
      "Epoch [3/50], Step [300/938], Loss D: 0.0893, Loss G: 6.4703\n",
      "Epoch [3/50], Step [400/938], Loss D: 0.1412, Loss G: 8.5188\n",
      "Epoch [3/50], Step [500/938], Loss D: 0.3510, Loss G: 6.5825\n",
      "Epoch [3/50], Step [600/938], Loss D: 0.4423, Loss G: 5.6239\n",
      "Epoch [3/50], Step [700/938], Loss D: 0.4071, Loss G: 5.9789\n",
      "Epoch [3/50], Step [800/938], Loss D: 0.1338, Loss G: 7.2350\n",
      "Epoch [3/50], Step [900/938], Loss D: 0.0669, Loss G: 5.1873\n",
      "Epoch [4/50], Step [100/938], Loss D: 0.1426, Loss G: 4.9210\n",
      "Epoch [4/50], Step [200/938], Loss D: 0.1168, Loss G: 5.8359\n",
      "Epoch [4/50], Step [300/938], Loss D: 0.3444, Loss G: 7.3303\n",
      "Epoch [4/50], Step [400/938], Loss D: 1.0054, Loss G: 6.6383\n",
      "Epoch [4/50], Step [500/938], Loss D: 0.0722, Loss G: 7.5755\n",
      "Epoch [4/50], Step [600/938], Loss D: 0.2565, Loss G: 5.6606\n",
      "Epoch [4/50], Step [700/938], Loss D: 0.2598, Loss G: 7.4956\n",
      "Epoch [4/50], Step [800/938], Loss D: 0.0824, Loss G: 4.9104\n",
      "Epoch [4/50], Step [900/938], Loss D: 0.3644, Loss G: 1.6990\n",
      "Epoch [5/50], Step [100/938], Loss D: 0.2645, Loss G: 4.6345\n",
      "Epoch [5/50], Step [200/938], Loss D: 0.2316, Loss G: 6.4116\n",
      "Epoch [5/50], Step [300/938], Loss D: 0.0697, Loss G: 4.5645\n",
      "Epoch [5/50], Step [400/938], Loss D: 0.0242, Loss G: 8.0258\n",
      "Epoch [5/50], Step [500/938], Loss D: 0.0244, Loss G: 8.0016\n",
      "Epoch [5/50], Step [600/938], Loss D: 0.1066, Loss G: 5.7752\n",
      "Epoch [5/50], Step [700/938], Loss D: 0.0903, Loss G: 6.6196\n",
      "Epoch [5/50], Step [800/938], Loss D: 0.2331, Loss G: 3.9516\n",
      "Epoch [5/50], Step [900/938], Loss D: 0.0452, Loss G: 7.8027\n",
      "Epoch [6/50], Step [100/938], Loss D: 0.1555, Loss G: 4.7350\n",
      "Epoch [6/50], Step [200/938], Loss D: 0.1610, Loss G: 4.2004\n",
      "Epoch [6/50], Step [300/938], Loss D: 0.0136, Loss G: 9.7938\n",
      "Epoch [6/50], Step [400/938], Loss D: 0.2837, Loss G: 7.0028\n",
      "Epoch [6/50], Step [500/938], Loss D: 0.0868, Loss G: 6.2431\n",
      "Epoch [6/50], Step [600/938], Loss D: 0.0441, Loss G: 11.3739\n",
      "Epoch [6/50], Step [700/938], Loss D: 0.1013, Loss G: 5.8761\n",
      "Epoch [6/50], Step [800/938], Loss D: 0.5023, Loss G: 8.6988\n",
      "Epoch [6/50], Step [900/938], Loss D: 0.1741, Loss G: 3.9220\n",
      "Epoch [7/50], Step [100/938], Loss D: 0.1172, Loss G: 6.3930\n",
      "Epoch [7/50], Step [200/938], Loss D: 0.0528, Loss G: 9.0777\n",
      "Epoch [7/50], Step [300/938], Loss D: 0.0605, Loss G: 5.1689\n",
      "Epoch [7/50], Step [400/938], Loss D: 0.0657, Loss G: 5.4877\n",
      "Epoch [7/50], Step [500/938], Loss D: 0.1646, Loss G: 4.3740\n",
      "Epoch [7/50], Step [600/938], Loss D: 0.1808, Loss G: 6.7900\n",
      "Epoch [7/50], Step [700/938], Loss D: 0.2227, Loss G: 7.1834\n",
      "Epoch [7/50], Step [800/938], Loss D: 0.2386, Loss G: 3.6526\n",
      "Epoch [7/50], Step [900/938], Loss D: 0.1804, Loss G: 5.6126\n",
      "Epoch [8/50], Step [100/938], Loss D: 0.2004, Loss G: 7.7003\n",
      "Epoch [8/50], Step [200/938], Loss D: 0.3236, Loss G: 4.2576\n",
      "Epoch [8/50], Step [300/938], Loss D: 0.1647, Loss G: 4.8916\n",
      "Epoch [8/50], Step [400/938], Loss D: 0.0282, Loss G: 9.0794\n",
      "Epoch [8/50], Step [500/938], Loss D: 0.1173, Loss G: 5.1887\n",
      "Epoch [8/50], Step [600/938], Loss D: 0.1211, Loss G: 8.7180\n",
      "Epoch [8/50], Step [700/938], Loss D: 0.4594, Loss G: 4.0347\n",
      "Epoch [8/50], Step [800/938], Loss D: 0.1593, Loss G: 5.9542\n",
      "Epoch [8/50], Step [900/938], Loss D: 0.3347, Loss G: 3.8555\n",
      "Epoch [9/50], Step [100/938], Loss D: 0.0797, Loss G: 5.3017\n",
      "Epoch [9/50], Step [200/938], Loss D: 0.0788, Loss G: 7.6702\n",
      "Epoch [9/50], Step [300/938], Loss D: 0.1149, Loss G: 4.5072\n",
      "Epoch [9/50], Step [400/938], Loss D: 0.2929, Loss G: 4.5261\n",
      "Epoch [9/50], Step [500/938], Loss D: 0.2200, Loss G: 5.1026\n",
      "Epoch [9/50], Step [600/938], Loss D: 0.1884, Loss G: 4.4499\n",
      "Epoch [9/50], Step [700/938], Loss D: 0.0956, Loss G: 5.9135\n",
      "Epoch [9/50], Step [800/938], Loss D: 0.3567, Loss G: 4.7950\n",
      "Epoch [9/50], Step [900/938], Loss D: 0.2216, Loss G: 4.0854\n",
      "Epoch [10/50], Step [100/938], Loss D: 0.2543, Loss G: 5.0266\n",
      "Epoch [10/50], Step [200/938], Loss D: 0.2233, Loss G: 4.8266\n",
      "Epoch [10/50], Step [300/938], Loss D: 0.4067, Loss G: 4.7113\n",
      "Epoch [10/50], Step [400/938], Loss D: 0.1441, Loss G: 4.3097\n",
      "Epoch [10/50], Step [500/938], Loss D: 0.1195, Loss G: 5.3475\n",
      "Epoch [10/50], Step [600/938], Loss D: 0.2866, Loss G: 4.2362\n",
      "Epoch [10/50], Step [700/938], Loss D: 0.1658, Loss G: 5.7351\n",
      "Epoch [10/50], Step [800/938], Loss D: 0.1030, Loss G: 3.7288\n",
      "Epoch [10/50], Step [900/938], Loss D: 0.2493, Loss G: 5.8957\n",
      "Epoch [11/50], Step [100/938], Loss D: 0.2121, Loss G: 5.6045\n",
      "Epoch [11/50], Step [200/938], Loss D: 0.0533, Loss G: 6.5012\n",
      "Epoch [11/50], Step [300/938], Loss D: 0.3979, Loss G: 4.4608\n",
      "Epoch [11/50], Step [400/938], Loss D: 0.0933, Loss G: 5.0134\n",
      "Epoch [11/50], Step [500/938], Loss D: 0.3171, Loss G: 5.2407\n",
      "Epoch [11/50], Step [600/938], Loss D: 0.1137, Loss G: 4.8184\n",
      "Epoch [11/50], Step [700/938], Loss D: 0.2643, Loss G: 6.5066\n",
      "Epoch [11/50], Step [800/938], Loss D: 0.1232, Loss G: 4.9502\n",
      "Epoch [11/50], Step [900/938], Loss D: 0.2911, Loss G: 3.4057\n",
      "Epoch [12/50], Step [100/938], Loss D: 0.1610, Loss G: 5.6203\n",
      "Epoch [12/50], Step [200/938], Loss D: 0.1900, Loss G: 6.0293\n",
      "Epoch [12/50], Step [300/938], Loss D: 0.3108, Loss G: 4.2689\n",
      "Epoch [12/50], Step [400/938], Loss D: 0.1778, Loss G: 4.8713\n",
      "Epoch [12/50], Step [500/938], Loss D: 0.1494, Loss G: 4.9997\n",
      "Epoch [12/50], Step [600/938], Loss D: 0.5762, Loss G: 3.7499\n",
      "Epoch [12/50], Step [700/938], Loss D: 0.2844, Loss G: 4.4120\n",
      "Epoch [12/50], Step [800/938], Loss D: 0.3919, Loss G: 5.8746\n",
      "Epoch [12/50], Step [900/938], Loss D: 0.2672, Loss G: 4.4387\n",
      "Epoch [13/50], Step [100/938], Loss D: 0.3423, Loss G: 3.7336\n",
      "Epoch [13/50], Step [200/938], Loss D: 0.1745, Loss G: 3.3831\n",
      "Epoch [13/50], Step [300/938], Loss D: 0.3048, Loss G: 4.8876\n",
      "Epoch [13/50], Step [400/938], Loss D: 0.2194, Loss G: 5.3054\n",
      "Epoch [13/50], Step [500/938], Loss D: 0.5522, Loss G: 3.5357\n",
      "Epoch [13/50], Step [600/938], Loss D: 0.3038, Loss G: 4.4702\n",
      "Epoch [13/50], Step [700/938], Loss D: 0.3635, Loss G: 3.3073\n",
      "Epoch [13/50], Step [800/938], Loss D: 0.2183, Loss G: 3.9303\n",
      "Epoch [13/50], Step [900/938], Loss D: 0.1610, Loss G: 6.4556\n",
      "Epoch [14/50], Step [100/938], Loss D: 0.3810, Loss G: 3.9173\n",
      "Epoch [14/50], Step [200/938], Loss D: 0.4270, Loss G: 4.6838\n",
      "Epoch [14/50], Step [300/938], Loss D: 0.2242, Loss G: 4.1956\n",
      "Epoch [14/50], Step [400/938], Loss D: 0.2174, Loss G: 4.3764\n",
      "Epoch [14/50], Step [500/938], Loss D: 0.3244, Loss G: 3.3595\n",
      "Epoch [14/50], Step [600/938], Loss D: 0.3662, Loss G: 4.3930\n",
      "Epoch [14/50], Step [700/938], Loss D: 0.3374, Loss G: 3.3575\n",
      "Epoch [14/50], Step [800/938], Loss D: 0.2561, Loss G: 2.7616\n",
      "Epoch [14/50], Step [900/938], Loss D: 0.1854, Loss G: 5.0724\n",
      "Epoch [15/50], Step [100/938], Loss D: 0.2247, Loss G: 3.5037\n",
      "Epoch [15/50], Step [200/938], Loss D: 0.3270, Loss G: 3.2782\n",
      "Epoch [15/50], Step [300/938], Loss D: 0.3434, Loss G: 4.5610\n",
      "Epoch [15/50], Step [400/938], Loss D: 0.9517, Loss G: 2.6338\n",
      "Epoch [15/50], Step [500/938], Loss D: 0.4823, Loss G: 3.3785\n",
      "Epoch [15/50], Step [600/938], Loss D: 0.2853, Loss G: 4.6660\n",
      "Epoch [15/50], Step [700/938], Loss D: 0.3930, Loss G: 2.7635\n",
      "Epoch [15/50], Step [800/938], Loss D: 0.5211, Loss G: 3.6183\n",
      "Epoch [15/50], Step [900/938], Loss D: 0.1803, Loss G: 3.2366\n",
      "Epoch [16/50], Step [100/938], Loss D: 0.4876, Loss G: 4.0877\n",
      "Epoch [16/50], Step [200/938], Loss D: 0.9708, Loss G: 3.3074\n",
      "Epoch [16/50], Step [300/938], Loss D: 0.3167, Loss G: 3.7169\n",
      "Epoch [16/50], Step [400/938], Loss D: 0.3262, Loss G: 4.8237\n",
      "Epoch [16/50], Step [500/938], Loss D: 0.2035, Loss G: 4.6259\n",
      "Epoch [16/50], Step [600/938], Loss D: 0.3516, Loss G: 3.4119\n",
      "Epoch [16/50], Step [700/938], Loss D: 0.4262, Loss G: 4.3053\n",
      "Epoch [16/50], Step [800/938], Loss D: 0.3910, Loss G: 3.2790\n",
      "Epoch [16/50], Step [900/938], Loss D: 0.3324, Loss G: 1.6863\n",
      "Epoch [17/50], Step [100/938], Loss D: 0.3558, Loss G: 3.5191\n",
      "Epoch [17/50], Step [200/938], Loss D: 0.3977, Loss G: 3.8186\n",
      "Epoch [17/50], Step [300/938], Loss D: 0.2787, Loss G: 4.3720\n",
      "Epoch [17/50], Step [400/938], Loss D: 0.3584, Loss G: 4.6758\n",
      "Epoch [17/50], Step [500/938], Loss D: 0.4226, Loss G: 2.8264\n",
      "Epoch [17/50], Step [600/938], Loss D: 0.5038, Loss G: 2.5076\n",
      "Epoch [17/50], Step [700/938], Loss D: 0.4486, Loss G: 3.4130\n",
      "Epoch [17/50], Step [800/938], Loss D: 0.4190, Loss G: 4.7858\n",
      "Epoch [17/50], Step [900/938], Loss D: 0.7114, Loss G: 3.3184\n",
      "Epoch [18/50], Step [100/938], Loss D: 0.5595, Loss G: 2.8118\n",
      "Epoch [18/50], Step [200/938], Loss D: 0.4935, Loss G: 2.7576\n",
      "Epoch [18/50], Step [300/938], Loss D: 0.3324, Loss G: 2.8418\n",
      "Epoch [18/50], Step [400/938], Loss D: 0.3213, Loss G: 3.9974\n",
      "Epoch [18/50], Step [500/938], Loss D: 0.4039, Loss G: 2.9431\n",
      "Epoch [18/50], Step [600/938], Loss D: 0.4124, Loss G: 1.6921\n",
      "Epoch [18/50], Step [700/938], Loss D: 0.2012, Loss G: 3.8999\n",
      "Epoch [18/50], Step [800/938], Loss D: 0.5577, Loss G: 2.7506\n",
      "Epoch [18/50], Step [900/938], Loss D: 0.4266, Loss G: 3.0554\n",
      "Epoch [19/50], Step [100/938], Loss D: 0.2960, Loss G: 2.9062\n",
      "Epoch [19/50], Step [200/938], Loss D: 0.5399, Loss G: 2.2305\n",
      "Epoch [19/50], Step [300/938], Loss D: 0.6237, Loss G: 2.0188\n",
      "Epoch [19/50], Step [400/938], Loss D: 0.3275, Loss G: 2.1101\n",
      "Epoch [19/50], Step [500/938], Loss D: 0.3391, Loss G: 2.8693\n",
      "Epoch [19/50], Step [600/938], Loss D: 0.4296, Loss G: 2.6793\n",
      "Epoch [19/50], Step [700/938], Loss D: 0.4839, Loss G: 1.7344\n",
      "Epoch [19/50], Step [800/938], Loss D: 0.5563, Loss G: 2.6152\n",
      "Epoch [19/50], Step [900/938], Loss D: 0.2913, Loss G: 2.8557\n",
      "Epoch [20/50], Step [100/938], Loss D: 0.4085, Loss G: 2.3227\n",
      "Epoch [20/50], Step [200/938], Loss D: 0.7934, Loss G: 2.3699\n",
      "Epoch [20/50], Step [300/938], Loss D: 0.6534, Loss G: 2.5446\n",
      "Epoch [20/50], Step [400/938], Loss D: 0.4360, Loss G: 1.6385\n",
      "Epoch [20/50], Step [500/938], Loss D: 0.4345, Loss G: 1.8101\n",
      "Epoch [20/50], Step [600/938], Loss D: 0.7471, Loss G: 2.3638\n",
      "Epoch [20/50], Step [700/938], Loss D: 0.4819, Loss G: 3.0273\n",
      "Epoch [20/50], Step [800/938], Loss D: 0.4200, Loss G: 2.8079\n",
      "Epoch [20/50], Step [900/938], Loss D: 0.4224, Loss G: 2.9637\n",
      "Epoch [21/50], Step [100/938], Loss D: 0.2122, Loss G: 3.1599\n",
      "Epoch [21/50], Step [200/938], Loss D: 0.5230, Loss G: 2.5647\n",
      "Epoch [21/50], Step [300/938], Loss D: 0.4845, Loss G: 2.3091\n",
      "Epoch [21/50], Step [400/938], Loss D: 0.3501, Loss G: 2.6003\n",
      "Epoch [21/50], Step [500/938], Loss D: 0.4272, Loss G: 2.8971\n",
      "Epoch [21/50], Step [600/938], Loss D: 0.9521, Loss G: 2.6088\n",
      "Epoch [21/50], Step [700/938], Loss D: 0.6018, Loss G: 2.3644\n",
      "Epoch [21/50], Step [800/938], Loss D: 0.5062, Loss G: 1.7925\n",
      "Epoch [21/50], Step [900/938], Loss D: 0.3175, Loss G: 2.6142\n",
      "Epoch [22/50], Step [100/938], Loss D: 0.4000, Loss G: 3.3465\n",
      "Epoch [22/50], Step [200/938], Loss D: 0.3597, Loss G: 3.9481\n",
      "Epoch [22/50], Step [300/938], Loss D: 0.6177, Loss G: 2.6047\n",
      "Epoch [22/50], Step [400/938], Loss D: 0.4801, Loss G: 1.9880\n",
      "Epoch [22/50], Step [500/938], Loss D: 0.6225, Loss G: 3.3666\n",
      "Epoch [22/50], Step [600/938], Loss D: 0.4759, Loss G: 2.1054\n",
      "Epoch [22/50], Step [700/938], Loss D: 0.3305, Loss G: 2.7798\n",
      "Epoch [22/50], Step [800/938], Loss D: 0.6120, Loss G: 2.7570\n",
      "Epoch [22/50], Step [900/938], Loss D: 0.5919, Loss G: 2.8631\n",
      "Epoch [23/50], Step [100/938], Loss D: 0.6692, Loss G: 2.1051\n",
      "Epoch [23/50], Step [200/938], Loss D: 0.4721, Loss G: 3.2484\n",
      "Epoch [23/50], Step [300/938], Loss D: 0.4893, Loss G: 2.7652\n",
      "Epoch [23/50], Step [400/938], Loss D: 0.5803, Loss G: 2.1504\n",
      "Epoch [23/50], Step [500/938], Loss D: 0.7531, Loss G: 2.2591\n",
      "Epoch [23/50], Step [600/938], Loss D: 0.5608, Loss G: 2.7090\n",
      "Epoch [23/50], Step [700/938], Loss D: 0.7264, Loss G: 2.2325\n",
      "Epoch [23/50], Step [800/938], Loss D: 0.5827, Loss G: 2.0167\n",
      "Epoch [23/50], Step [900/938], Loss D: 0.5774, Loss G: 2.9194\n",
      "Epoch [24/50], Step [100/938], Loss D: 0.4005, Loss G: 2.2479\n",
      "Epoch [24/50], Step [200/938], Loss D: 0.8731, Loss G: 2.3353\n",
      "Epoch [24/50], Step [300/938], Loss D: 0.6235, Loss G: 2.2274\n",
      "Epoch [24/50], Step [400/938], Loss D: 0.7047, Loss G: 3.0717\n",
      "Epoch [24/50], Step [500/938], Loss D: 0.6890, Loss G: 2.2490\n",
      "Epoch [24/50], Step [600/938], Loss D: 0.3624, Loss G: 2.4528\n",
      "Epoch [24/50], Step [700/938], Loss D: 0.6074, Loss G: 3.0106\n",
      "Epoch [24/50], Step [800/938], Loss D: 0.6536, Loss G: 1.7111\n",
      "Epoch [24/50], Step [900/938], Loss D: 0.6461, Loss G: 2.3470\n",
      "Epoch [25/50], Step [100/938], Loss D: 0.5285, Loss G: 2.2607\n",
      "Epoch [25/50], Step [200/938], Loss D: 0.7024, Loss G: 2.4785\n",
      "Epoch [25/50], Step [300/938], Loss D: 0.6483, Loss G: 2.4017\n",
      "Epoch [25/50], Step [400/938], Loss D: 0.5524, Loss G: 2.1094\n",
      "Epoch [25/50], Step [500/938], Loss D: 0.4953, Loss G: 1.9625\n",
      "Epoch [25/50], Step [600/938], Loss D: 0.6029, Loss G: 1.6895\n",
      "Epoch [25/50], Step [700/938], Loss D: 0.5679, Loss G: 2.2601\n",
      "Epoch [25/50], Step [800/938], Loss D: 0.5734, Loss G: 2.1361\n",
      "Epoch [25/50], Step [900/938], Loss D: 1.0182, Loss G: 2.2897\n",
      "Epoch [26/50], Step [100/938], Loss D: 0.7818, Loss G: 2.2775\n",
      "Epoch [26/50], Step [200/938], Loss D: 0.7131, Loss G: 1.8020\n",
      "Epoch [26/50], Step [300/938], Loss D: 0.3649, Loss G: 2.2062\n",
      "Epoch [26/50], Step [400/938], Loss D: 0.5668, Loss G: 2.2182\n",
      "Epoch [26/50], Step [500/938], Loss D: 0.7889, Loss G: 1.4522\n",
      "Epoch [26/50], Step [600/938], Loss D: 0.6353, Loss G: 2.5216\n",
      "Epoch [26/50], Step [700/938], Loss D: 0.9253, Loss G: 1.7962\n",
      "Epoch [26/50], Step [800/938], Loss D: 0.7589, Loss G: 2.3319\n",
      "Epoch [26/50], Step [900/938], Loss D: 0.4544, Loss G: 2.1267\n",
      "Epoch [27/50], Step [100/938], Loss D: 0.4411, Loss G: 2.4771\n",
      "Epoch [27/50], Step [200/938], Loss D: 0.6796, Loss G: 1.6056\n",
      "Epoch [27/50], Step [300/938], Loss D: 0.6144, Loss G: 2.8813\n",
      "Epoch [27/50], Step [400/938], Loss D: 0.5775, Loss G: 1.9081\n",
      "Epoch [27/50], Step [500/938], Loss D: 0.6917, Loss G: 2.2465\n",
      "Epoch [27/50], Step [600/938], Loss D: 0.6125, Loss G: 2.4839\n",
      "Epoch [27/50], Step [700/938], Loss D: 0.6410, Loss G: 2.0369\n",
      "Epoch [27/50], Step [800/938], Loss D: 0.6910, Loss G: 1.5048\n",
      "Epoch [27/50], Step [900/938], Loss D: 0.5450, Loss G: 2.2545\n",
      "Epoch [28/50], Step [100/938], Loss D: 0.7081, Loss G: 2.2835\n",
      "Epoch [28/50], Step [200/938], Loss D: 0.6382, Loss G: 1.8749\n",
      "Epoch [28/50], Step [300/938], Loss D: 0.6608, Loss G: 1.5562\n",
      "Epoch [28/50], Step [400/938], Loss D: 0.6670, Loss G: 2.3104\n",
      "Epoch [28/50], Step [500/938], Loss D: 0.4132, Loss G: 2.4523\n",
      "Epoch [28/50], Step [600/938], Loss D: 0.7801, Loss G: 2.1423\n",
      "Epoch [28/50], Step [700/938], Loss D: 0.8788, Loss G: 2.0398\n",
      "Epoch [28/50], Step [800/938], Loss D: 0.5669, Loss G: 2.4545\n",
      "Epoch [28/50], Step [900/938], Loss D: 0.7126, Loss G: 1.6883\n",
      "Epoch [29/50], Step [100/938], Loss D: 0.6472, Loss G: 2.3310\n",
      "Epoch [29/50], Step [200/938], Loss D: 0.6109, Loss G: 2.2213\n",
      "Epoch [29/50], Step [300/938], Loss D: 0.7684, Loss G: 2.2373\n",
      "Epoch [29/50], Step [400/938], Loss D: 0.4930, Loss G: 2.2555\n",
      "Epoch [29/50], Step [500/938], Loss D: 0.5751, Loss G: 1.9921\n",
      "Epoch [29/50], Step [600/938], Loss D: 0.5659, Loss G: 2.5720\n",
      "Epoch [29/50], Step [700/938], Loss D: 0.5416, Loss G: 1.9599\n",
      "Epoch [29/50], Step [800/938], Loss D: 0.6963, Loss G: 1.8428\n",
      "Epoch [29/50], Step [900/938], Loss D: 0.9650, Loss G: 1.5438\n",
      "Epoch [30/50], Step [100/938], Loss D: 0.7822, Loss G: 2.3094\n",
      "Epoch [30/50], Step [200/938], Loss D: 0.6582, Loss G: 2.5001\n",
      "Epoch [30/50], Step [300/938], Loss D: 0.7457, Loss G: 2.0950\n",
      "Epoch [30/50], Step [400/938], Loss D: 0.9772, Loss G: 1.7464\n",
      "Epoch [30/50], Step [500/938], Loss D: 0.6799, Loss G: 1.7912\n",
      "Epoch [30/50], Step [600/938], Loss D: 0.6442, Loss G: 1.8372\n",
      "Epoch [30/50], Step [700/938], Loss D: 0.6332, Loss G: 1.8843\n",
      "Epoch [30/50], Step [800/938], Loss D: 0.6445, Loss G: 2.1722\n",
      "Epoch [30/50], Step [900/938], Loss D: 0.6387, Loss G: 1.8905\n",
      "Epoch [31/50], Step [100/938], Loss D: 0.6401, Loss G: 1.9947\n",
      "Epoch [31/50], Step [200/938], Loss D: 0.5770, Loss G: 1.9777\n",
      "Epoch [31/50], Step [300/938], Loss D: 0.6410, Loss G: 1.4801\n",
      "Epoch [31/50], Step [400/938], Loss D: 0.8932, Loss G: 1.5040\n",
      "Epoch [31/50], Step [500/938], Loss D: 0.6528, Loss G: 1.8515\n",
      "Epoch [31/50], Step [600/938], Loss D: 0.7810, Loss G: 1.8542\n",
      "Epoch [31/50], Step [700/938], Loss D: 0.6649, Loss G: 1.8931\n",
      "Epoch [31/50], Step [800/938], Loss D: 0.8419, Loss G: 2.2624\n",
      "Epoch [31/50], Step [900/938], Loss D: 0.6711, Loss G: 1.9825\n",
      "Epoch [32/50], Step [100/938], Loss D: 0.6522, Loss G: 1.8423\n",
      "Epoch [32/50], Step [200/938], Loss D: 0.6270, Loss G: 2.0582\n",
      "Epoch [32/50], Step [300/938], Loss D: 0.5572, Loss G: 2.4003\n",
      "Epoch [32/50], Step [400/938], Loss D: 0.6371, Loss G: 2.0229\n",
      "Epoch [32/50], Step [500/938], Loss D: 0.6941, Loss G: 1.8420\n",
      "Epoch [32/50], Step [600/938], Loss D: 0.8029, Loss G: 1.7065\n",
      "Epoch [32/50], Step [700/938], Loss D: 0.7707, Loss G: 1.4378\n",
      "Epoch [32/50], Step [800/938], Loss D: 0.9365, Loss G: 1.6102\n",
      "Epoch [32/50], Step [900/938], Loss D: 0.7233, Loss G: 2.3675\n",
      "Epoch [33/50], Step [100/938], Loss D: 0.7524, Loss G: 2.1629\n",
      "Epoch [33/50], Step [200/938], Loss D: 0.6902, Loss G: 2.2844\n",
      "Epoch [33/50], Step [300/938], Loss D: 0.7920, Loss G: 1.7452\n",
      "Epoch [33/50], Step [400/938], Loss D: 0.8707, Loss G: 2.0944\n",
      "Epoch [33/50], Step [500/938], Loss D: 0.7839, Loss G: 1.8316\n",
      "Epoch [33/50], Step [600/938], Loss D: 0.7620, Loss G: 1.9753\n",
      "Epoch [33/50], Step [700/938], Loss D: 0.8415, Loss G: 1.2991\n",
      "Epoch [33/50], Step [800/938], Loss D: 1.1714, Loss G: 2.1124\n",
      "Epoch [33/50], Step [900/938], Loss D: 0.6291, Loss G: 1.9186\n",
      "Epoch [34/50], Step [100/938], Loss D: 0.8921, Loss G: 2.4649\n",
      "Epoch [34/50], Step [200/938], Loss D: 0.6004, Loss G: 2.1695\n",
      "Epoch [34/50], Step [300/938], Loss D: 0.6994, Loss G: 1.8081\n",
      "Epoch [34/50], Step [400/938], Loss D: 0.4967, Loss G: 2.1741\n",
      "Epoch [34/50], Step [500/938], Loss D: 0.6674, Loss G: 1.7136\n",
      "Epoch [34/50], Step [600/938], Loss D: 0.5373, Loss G: 2.2633\n",
      "Epoch [34/50], Step [700/938], Loss D: 0.6890, Loss G: 1.4427\n",
      "Epoch [34/50], Step [800/938], Loss D: 0.7497, Loss G: 2.0402\n",
      "Epoch [34/50], Step [900/938], Loss D: 0.6073, Loss G: 1.7092\n",
      "Epoch [35/50], Step [100/938], Loss D: 0.9229, Loss G: 1.6631\n",
      "Epoch [35/50], Step [200/938], Loss D: 0.8255, Loss G: 1.5209\n",
      "Epoch [35/50], Step [300/938], Loss D: 0.7930, Loss G: 1.5773\n",
      "Epoch [35/50], Step [400/938], Loss D: 0.7531, Loss G: 1.9784\n",
      "Epoch [35/50], Step [500/938], Loss D: 0.6051, Loss G: 2.3164\n",
      "Epoch [35/50], Step [600/938], Loss D: 0.7904, Loss G: 1.8822\n",
      "Epoch [35/50], Step [700/938], Loss D: 0.7427, Loss G: 1.4656\n",
      "Epoch [35/50], Step [800/938], Loss D: 0.5514, Loss G: 2.3072\n",
      "Epoch [35/50], Step [900/938], Loss D: 0.6361, Loss G: 2.0146\n",
      "Epoch [36/50], Step [100/938], Loss D: 0.8902, Loss G: 1.8066\n",
      "Epoch [36/50], Step [200/938], Loss D: 0.7304, Loss G: 1.7408\n",
      "Epoch [36/50], Step [300/938], Loss D: 0.8106, Loss G: 1.6678\n",
      "Epoch [36/50], Step [400/938], Loss D: 0.6892, Loss G: 2.0228\n",
      "Epoch [36/50], Step [500/938], Loss D: 0.8007, Loss G: 1.9848\n",
      "Epoch [36/50], Step [600/938], Loss D: 0.8348, Loss G: 1.5791\n",
      "Epoch [36/50], Step [700/938], Loss D: 0.8443, Loss G: 1.9374\n",
      "Epoch [36/50], Step [800/938], Loss D: 1.0214, Loss G: 1.9553\n",
      "Epoch [36/50], Step [900/938], Loss D: 0.7623, Loss G: 1.6974\n",
      "Epoch [37/50], Step [100/938], Loss D: 0.8773, Loss G: 1.2253\n",
      "Epoch [37/50], Step [200/938], Loss D: 0.9361, Loss G: 1.7753\n",
      "Epoch [37/50], Step [300/938], Loss D: 0.7536, Loss G: 1.5435\n",
      "Epoch [37/50], Step [400/938], Loss D: 0.7659, Loss G: 1.7179\n",
      "Epoch [37/50], Step [500/938], Loss D: 0.6257, Loss G: 1.9605\n",
      "Epoch [37/50], Step [600/938], Loss D: 0.7853, Loss G: 1.4890\n",
      "Epoch [37/50], Step [700/938], Loss D: 0.6809, Loss G: 2.1055\n",
      "Epoch [37/50], Step [800/938], Loss D: 0.7781, Loss G: 2.1883\n",
      "Epoch [37/50], Step [900/938], Loss D: 0.7214, Loss G: 1.5963\n",
      "Epoch [38/50], Step [100/938], Loss D: 0.6628, Loss G: 1.8469\n",
      "Epoch [38/50], Step [200/938], Loss D: 0.8579, Loss G: 1.4795\n",
      "Epoch [38/50], Step [300/938], Loss D: 0.8693, Loss G: 1.8883\n",
      "Epoch [38/50], Step [400/938], Loss D: 0.7552, Loss G: 1.3290\n",
      "Epoch [38/50], Step [500/938], Loss D: 0.6850, Loss G: 1.6841\n",
      "Epoch [38/50], Step [600/938], Loss D: 0.7588, Loss G: 1.7366\n",
      "Epoch [38/50], Step [700/938], Loss D: 0.7287, Loss G: 1.9390\n",
      "Epoch [38/50], Step [800/938], Loss D: 0.8207, Loss G: 1.3695\n",
      "Epoch [38/50], Step [900/938], Loss D: 0.7715, Loss G: 2.0912\n",
      "Epoch [39/50], Step [100/938], Loss D: 0.6684, Loss G: 2.0222\n",
      "Epoch [39/50], Step [200/938], Loss D: 0.8927, Loss G: 1.3230\n",
      "Epoch [39/50], Step [300/938], Loss D: 0.6622, Loss G: 2.2008\n",
      "Epoch [39/50], Step [400/938], Loss D: 0.7769, Loss G: 1.8051\n",
      "Epoch [39/50], Step [500/938], Loss D: 0.7096, Loss G: 1.8918\n",
      "Epoch [39/50], Step [600/938], Loss D: 1.0581, Loss G: 1.8267\n",
      "Epoch [39/50], Step [700/938], Loss D: 0.9478, Loss G: 1.4664\n",
      "Epoch [39/50], Step [800/938], Loss D: 0.6817, Loss G: 1.8724\n",
      "Epoch [39/50], Step [900/938], Loss D: 0.8479, Loss G: 1.7336\n",
      "Epoch [40/50], Step [100/938], Loss D: 0.7285, Loss G: 1.5557\n",
      "Epoch [40/50], Step [200/938], Loss D: 0.9042, Loss G: 1.9744\n",
      "Epoch [40/50], Step [300/938], Loss D: 0.9003, Loss G: 1.3759\n",
      "Epoch [40/50], Step [400/938], Loss D: 0.8251, Loss G: 1.6206\n",
      "Epoch [40/50], Step [500/938], Loss D: 0.6604, Loss G: 1.8917\n",
      "Epoch [40/50], Step [600/938], Loss D: 0.9242, Loss G: 1.2777\n",
      "Epoch [40/50], Step [700/938], Loss D: 0.7429, Loss G: 1.5602\n",
      "Epoch [40/50], Step [800/938], Loss D: 0.8265, Loss G: 1.8899\n",
      "Epoch [40/50], Step [900/938], Loss D: 0.7941, Loss G: 1.3207\n",
      "Epoch [41/50], Step [100/938], Loss D: 0.7500, Loss G: 1.7352\n",
      "Epoch [41/50], Step [200/938], Loss D: 0.7758, Loss G: 1.5494\n",
      "Epoch [41/50], Step [300/938], Loss D: 0.9077, Loss G: 1.6999\n",
      "Epoch [41/50], Step [400/938], Loss D: 0.8021, Loss G: 1.6557\n",
      "Epoch [41/50], Step [500/938], Loss D: 0.5637, Loss G: 1.8444\n",
      "Epoch [41/50], Step [600/938], Loss D: 0.8383, Loss G: 1.7546\n",
      "Epoch [41/50], Step [700/938], Loss D: 0.9635, Loss G: 1.2822\n",
      "Epoch [41/50], Step [800/938], Loss D: 0.6531, Loss G: 1.6647\n",
      "Epoch [41/50], Step [900/938], Loss D: 0.8182, Loss G: 1.8271\n",
      "Epoch [42/50], Step [100/938], Loss D: 0.7107, Loss G: 1.9821\n",
      "Epoch [42/50], Step [200/938], Loss D: 0.7272, Loss G: 1.7621\n",
      "Epoch [42/50], Step [300/938], Loss D: 0.7487, Loss G: 1.6321\n",
      "Epoch [42/50], Step [400/938], Loss D: 0.7317, Loss G: 1.5213\n",
      "Epoch [42/50], Step [500/938], Loss D: 0.9337, Loss G: 1.5038\n",
      "Epoch [42/50], Step [600/938], Loss D: 0.7360, Loss G: 1.7615\n",
      "Epoch [42/50], Step [700/938], Loss D: 0.9564, Loss G: 1.3916\n",
      "Epoch [42/50], Step [800/938], Loss D: 0.9733, Loss G: 1.3288\n",
      "Epoch [42/50], Step [900/938], Loss D: 0.7269, Loss G: 1.7429\n",
      "Epoch [43/50], Step [100/938], Loss D: 0.8771, Loss G: 1.3706\n",
      "Epoch [43/50], Step [200/938], Loss D: 0.8816, Loss G: 1.4703\n",
      "Epoch [43/50], Step [300/938], Loss D: 0.9237, Loss G: 1.3352\n",
      "Epoch [43/50], Step [400/938], Loss D: 0.8891, Loss G: 1.3426\n",
      "Epoch [43/50], Step [500/938], Loss D: 0.8820, Loss G: 1.4101\n",
      "Epoch [43/50], Step [600/938], Loss D: 0.7749, Loss G: 1.6293\n",
      "Epoch [43/50], Step [700/938], Loss D: 0.8089, Loss G: 1.8034\n",
      "Epoch [43/50], Step [800/938], Loss D: 0.9156, Loss G: 1.3990\n",
      "Epoch [43/50], Step [900/938], Loss D: 0.7643, Loss G: 1.6555\n",
      "Epoch [44/50], Step [100/938], Loss D: 0.8902, Loss G: 1.5470\n",
      "Epoch [44/50], Step [200/938], Loss D: 0.7800, Loss G: 1.6430\n",
      "Epoch [44/50], Step [300/938], Loss D: 0.6849, Loss G: 1.6126\n",
      "Epoch [44/50], Step [400/938], Loss D: 0.7138, Loss G: 1.5978\n",
      "Epoch [44/50], Step [500/938], Loss D: 0.9112, Loss G: 1.3794\n",
      "Epoch [44/50], Step [600/938], Loss D: 1.0069, Loss G: 1.3636\n",
      "Epoch [44/50], Step [700/938], Loss D: 0.7449, Loss G: 1.7999\n",
      "Epoch [44/50], Step [800/938], Loss D: 1.0029, Loss G: 1.5650\n",
      "Epoch [44/50], Step [900/938], Loss D: 0.8596, Loss G: 1.5380\n",
      "Epoch [45/50], Step [100/938], Loss D: 0.8608, Loss G: 1.5569\n",
      "Epoch [45/50], Step [200/938], Loss D: 0.8904, Loss G: 1.6931\n",
      "Epoch [45/50], Step [300/938], Loss D: 0.8765, Loss G: 1.2990\n",
      "Epoch [45/50], Step [400/938], Loss D: 0.9810, Loss G: 1.5481\n",
      "Epoch [45/50], Step [500/938], Loss D: 0.7817, Loss G: 1.6874\n",
      "Epoch [45/50], Step [600/938], Loss D: 0.9685, Loss G: 1.4877\n",
      "Epoch [45/50], Step [700/938], Loss D: 0.8722, Loss G: 1.2010\n",
      "Epoch [45/50], Step [800/938], Loss D: 0.8577, Loss G: 1.4220\n",
      "Epoch [45/50], Step [900/938], Loss D: 1.0886, Loss G: 1.7031\n",
      "Epoch [46/50], Step [100/938], Loss D: 0.7880, Loss G: 1.8559\n",
      "Epoch [46/50], Step [200/938], Loss D: 0.9811, Loss G: 1.9174\n",
      "Epoch [46/50], Step [300/938], Loss D: 0.8007, Loss G: 1.7742\n",
      "Epoch [46/50], Step [400/938], Loss D: 0.7800, Loss G: 1.9414\n",
      "Epoch [46/50], Step [500/938], Loss D: 0.6964, Loss G: 1.5959\n",
      "Epoch [46/50], Step [600/938], Loss D: 0.9159, Loss G: 1.7582\n",
      "Epoch [46/50], Step [700/938], Loss D: 0.8237, Loss G: 1.5251\n",
      "Epoch [46/50], Step [800/938], Loss D: 0.8084, Loss G: 1.6497\n",
      "Epoch [46/50], Step [900/938], Loss D: 0.9704, Loss G: 1.2967\n",
      "Epoch [47/50], Step [100/938], Loss D: 0.7221, Loss G: 1.7582\n",
      "Epoch [47/50], Step [200/938], Loss D: 1.0301, Loss G: 1.5922\n",
      "Epoch [47/50], Step [300/938], Loss D: 0.7751, Loss G: 1.6809\n",
      "Epoch [47/50], Step [400/938], Loss D: 0.7691, Loss G: 1.4165\n",
      "Epoch [47/50], Step [500/938], Loss D: 0.8050, Loss G: 1.5815\n",
      "Epoch [47/50], Step [600/938], Loss D: 0.9819, Loss G: 1.4150\n",
      "Epoch [47/50], Step [700/938], Loss D: 0.8311, Loss G: 1.6793\n",
      "Epoch [47/50], Step [800/938], Loss D: 0.8852, Loss G: 1.4538\n",
      "Epoch [47/50], Step [900/938], Loss D: 1.0612, Loss G: 1.2339\n",
      "Epoch [48/50], Step [100/938], Loss D: 0.7858, Loss G: 1.5576\n",
      "Epoch [48/50], Step [200/938], Loss D: 0.6966, Loss G: 1.7173\n",
      "Epoch [48/50], Step [300/938], Loss D: 0.9828, Loss G: 1.5109\n",
      "Epoch [48/50], Step [400/938], Loss D: 0.7680, Loss G: 1.2421\n",
      "Epoch [48/50], Step [500/938], Loss D: 0.8378, Loss G: 1.7776\n",
      "Epoch [48/50], Step [600/938], Loss D: 0.9447, Loss G: 1.3178\n",
      "Epoch [48/50], Step [700/938], Loss D: 0.8110, Loss G: 1.4254\n",
      "Epoch [48/50], Step [800/938], Loss D: 0.8225, Loss G: 1.4456\n",
      "Epoch [48/50], Step [900/938], Loss D: 0.8280, Loss G: 1.4660\n",
      "Epoch [49/50], Step [100/938], Loss D: 0.7688, Loss G: 1.4848\n",
      "Epoch [49/50], Step [200/938], Loss D: 0.9069, Loss G: 1.2625\n",
      "Epoch [49/50], Step [300/938], Loss D: 0.7917, Loss G: 1.6071\n",
      "Epoch [49/50], Step [400/938], Loss D: 1.0987, Loss G: 1.2112\n",
      "Epoch [49/50], Step [500/938], Loss D: 0.8279, Loss G: 1.3536\n",
      "Epoch [49/50], Step [600/938], Loss D: 0.9134, Loss G: 1.4125\n",
      "Epoch [49/50], Step [700/938], Loss D: 0.9471, Loss G: 1.9518\n",
      "Epoch [49/50], Step [800/938], Loss D: 0.8296, Loss G: 1.4918\n",
      "Epoch [49/50], Step [900/938], Loss D: 1.0378, Loss G: 1.5150\n",
      "Epoch [50/50], Step [100/938], Loss D: 0.9025, Loss G: 1.6965\n",
      "Epoch [50/50], Step [200/938], Loss D: 0.9645, Loss G: 1.4678\n",
      "Epoch [50/50], Step [300/938], Loss D: 0.8129, Loss G: 1.4869\n",
      "Epoch [50/50], Step [400/938], Loss D: 0.8144, Loss G: 1.9336\n",
      "Epoch [50/50], Step [500/938], Loss D: 0.8517, Loss G: 1.2726\n",
      "Epoch [50/50], Step [600/938], Loss D: 0.7378, Loss G: 1.9214\n",
      "Epoch [50/50], Step [700/938], Loss D: 0.7792, Loss G: 1.4081\n",
      "Epoch [50/50], Step [800/938], Loss D: 0.7195, Loss G: 1.8647\n",
      "Epoch [50/50], Step [900/938], Loss D: 0.9200, Loss G: 1.4240\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "noise_dim = 100\n",
    "os.makedirs('mnist_results', exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        batch_size = images.size(0)\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        discriminator.zero_grad()\n",
    "        outputs = discriminator(images.to(device)).view(-1, 1)\n",
    "        loss_d_real = criterion(outputs, real_labels)\n",
    "        loss_d_real.backward()\n",
    "        \n",
    "        z = get_noise(batch_size, noise_dim)\n",
    "        fake_images = generator(z)\n",
    "        outputs = discriminator(fake_images.detach()).view(-1, 1)\n",
    "        loss_d_fake = criterion(outputs, fake_labels)\n",
    "        loss_d_fake.backward()\n",
    "        \n",
    "        loss_d = loss_d_fake + loss_d_real\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        generator.zero_grad()\n",
    "        outputs = discriminator(fake_images).view(-1, 1)\n",
    "        loss_g = criterion(outputs, real_labels)\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss D: {loss_d.item():.4f}, Loss G: {loss_g.item():.4f}')\n",
    "    \n",
    "    fake_images = fake_images.reshape(batch_size, 1, 28, 28)\n",
    "    if (epoch + 1) % 5 == 5:\n",
    "        vutils.save_image(fake_images, f'mnist_results/fake_img_epoch_{epoch+1}.png', normalize=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SC4001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
